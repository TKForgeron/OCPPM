{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:-------------------------------- TEST CS HOEG --------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz (4x)\n",
      "Total CPU memory: 46.93GB\n",
      "Available CPU memory: 29.56GB\n",
      "GPU: NVIDIA GeForce GTX 960\n",
      "Total GPU memory: 4096.0MB\n",
      "Available GPU memory: 4029.0MB\n",
      "Platform: Linux-5.19.0-46-generic-x86_64-with-glibc2.35\n",
      "Torch version: 1.13.1+cu117\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# DEPENDENCIES\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/tim/Development/OCPPM/\")\n",
    "import functools\n",
    "import json\n",
    "import pprint\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ocpa.algo.predictive_monitoring.factory as feature_factory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as O\n",
    "import torch.utils.tensorboard\n",
    "import torch_geometric.loader as L\n",
    "import torch_geometric.nn as pygnn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "import utilities.evaluation_utils as evaluation_utils\n",
    "import utilities.hetero_data_utils as hetero_data_utils\n",
    "import utilities.hetero_evaluation_utils as hetero_evaluation_utils\n",
    "import utilities.hetero_training_utils as hetero_training_utils\n",
    "import utilities.torch_utils as torch_utils\n",
    "\n",
    "# Custom imports\n",
    "from models.definitions.geometric_models import GraphModel, HeteroHigherOrderGNN\n",
    "\n",
    "# Print system info\n",
    "torch_utils.print_system_info()\n",
    "torch_utils.print_torch_info()\n",
    "\n",
    "# INITIAL CONFIGURATION\n",
    "# our target is @@object_lifecycle_duration, a regression target\n",
    "cs_ofg_config = {\n",
    "    \"ofg_file\": \"data/CS/feature_encodings/OFG/ofg/raw/CS_OFG.pkl\",\n",
    "    \"model_output_path\": \"models/CS/ofg\",\n",
    "    \"BATCH_SIZE\": 256,\n",
    "    \"RANDOM_SEED\": 42,\n",
    "    \"EPOCHS\": 30,\n",
    "    \"target_node_type\": \"krs\",\n",
    "    \"meta_data\": (\n",
    "        [\"krs\", \"krv\", \"cv\"],\n",
    "        [\n",
    "            (\"krs\", \"interacts\", \"krv\"),\n",
    "            (\"cv\", \"interacts\", \"krv\"),\n",
    "            (\"cv\", \"interacts\", \"krs\"),\n",
    "            (\"krv\", \"rev_interacts\", \"krs\"),\n",
    "            (\"krv\", \"rev_interacts\", \"cv\"),\n",
    "            (\"krs\", \"rev_interacts\", \"cv\"),\n",
    "        ],\n",
    "    ),\n",
    "    \"early_stopping\": 3,\n",
    "    \"optimizer\": O.Adam,\n",
    "    \"optimizer_settings\": {\n",
    "        \"lr\": 1e-3,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-08,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": False,\n",
    "    },\n",
    "    \"loss_fn\": torch.nn.L1Loss(),\n",
    "    \"verbose\": True,\n",
    "    \"skip_cache\": False,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "# CONFIGURATION ADAPTATIONS may be set here\n",
    "cs_ofg_config[\"BATCH_SIZE\"] = 512\n",
    "cs_ofg_config[\"EPOCHS\"] = 32\n",
    "cs_ofg_config[\"early_stopping\"] = 4\n",
    "cs_ofg_config[\"verbose\"] = False\n",
    "# cs_ofg_config[\"optimizer_settings\"]['lr']=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# DATA PREPARATION\n",
    "# Load HeteroData object from a pickle file using the specified file path\n",
    "with open(cs_ofg_config[\"ofg_file\"], \"rb\") as fp:\n",
    "    data: HeteroData = pickle.load(fp)\n",
    "# Define a list of transformations to be applied in sequence\n",
    "torch.manual_seed(cs_ofg_config[\"RANDOM_SEED\"])\n",
    "transformations = [\n",
    "    T.ToUndirected(),  # Convert the graph to an undirected graph\n",
    "    T.AddSelfLoops(),  # Add self-loops to the graph\n",
    "    T.NormalizeFeatures(),  # Normalize node features of the graph\n",
    "    T.RandomNodeSplit(\n",
    "        num_val=0.8 * 0.2, num_test=0.2\n",
    "    ),  # Split the graph into train, validation, and test sets based on random node assignment\n",
    "]\n",
    "# Apply the transformation pipeline to the data at once\n",
    "data = T.Compose(transformations)(data)\n",
    "# Create hetero dataloaders for each split\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    ") = hetero_data_utils.hetero_dataloaders_from_hetero_data(\n",
    "    hetero_data=data,\n",
    "    batch_size=cs_ofg_config[\"BATCH_SIZE\"],\n",
    "    num_neighbors=[3] * 2,\n",
    "    node_type=cs_ofg_config[\"target_node_type\"],\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    generator=torch.Generator().manual_seed(cs_ofg_config[\"RANDOM_SEED\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mkrs\u001b[0m={\n",
       "    y=[205995],\n",
       "    x=[205995, 21],\n",
       "    train_mask=[205995],\n",
       "    val_mask=[205995],\n",
       "    test_mask=[205995]\n",
       "  },\n",
       "  \u001b[1mkrv\u001b[0m={\n",
       "    y=[111427],\n",
       "    x=[111427, 21],\n",
       "    train_mask=[111427],\n",
       "    val_mask=[111427],\n",
       "    test_mask=[111427]\n",
       "  },\n",
       "  \u001b[1mcv\u001b[0m={\n",
       "    y=[6613],\n",
       "    x=[6613, 21],\n",
       "    train_mask=[6613],\n",
       "    val_mask=[6613],\n",
       "    test_mask=[6613]\n",
       "  },\n",
       "  \u001b[1m(krs, interacts, krv)\u001b[0m={ edge_index=[2, 73007] },\n",
       "  \u001b[1m(cv, interacts, krv)\u001b[0m={ edge_index=[2, 2173] },\n",
       "  \u001b[1m(cv, interacts, krs)\u001b[0m={ edge_index=[2, 15] },\n",
       "  \u001b[1m(krv, rev_interacts, krs)\u001b[0m={ edge_index=[2, 73007] },\n",
       "  \u001b[1m(krv, rev_interacts, cv)\u001b[0m={ edge_index=[2, 2173] },\n",
       "  \u001b[1m(krs, rev_interacts, cv)\u001b[0m={ edge_index=[2, 15] }\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:379: UserWarning: 'act1' will be duplicated, but its parameters cannot be reset. To suppress this warning, add a 'reset_parameters()' method to 'act1'\n",
      "  warnings.warn(\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:379: UserWarning: 'act2' will be duplicated, but its parameters cannot be reset. To suppress this warning, add a 'reset_parameters()' method to 'act2'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 66249\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# MODEL INITIATION\n",
    "class HeteroHigherOrderGNN(GraphModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int = 32,\n",
    "        out_channels: int = 1,\n",
    "        regression_target: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = pygnn.GraphConv(-1, hidden_channels)\n",
    "        self.conv2 = pygnn.GraphConv(-1, hidden_channels)\n",
    "        self.act1 = nn.PReLU()\n",
    "        self.act2 = nn.PReLU()\n",
    "        self.lin_out = pygnn.Linear(-1, out_channels)\n",
    "        self.probs_out = lambda x: x\n",
    "        if not regression_target:\n",
    "            self.probs_out = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin_out(x)\n",
    "        return self.probs_out(x)\n",
    "\n",
    "\n",
    "model = HeteroHigherOrderGNN(64, 1)\n",
    "model = pygnn.to_hetero(model, cs_ofg_config[\"meta_data\"])\n",
    "model.double()\n",
    "\n",
    "# Print summary of data and model\n",
    "# if cs_ofg_config[\"verbose\"]:\n",
    "# print(model)\n",
    "with torch.no_grad():  # Initialize lazy modules, s.t. we can count its parameters.\n",
    "    batch = next(iter(train_loader))\n",
    "    batch.to(cs_ofg_config[\"device\"])\n",
    "    model.to(cs_ofg_config[\"device\"])\n",
    "    out = model(batch.x_dict, batch.edge_index_dict)\n",
    "    print(f\"Number of parameters: {torch_utils.count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started, progress available in Tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [00:04<00:00, 56.23it/s]\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([513])) that is different to the input size (torch.Size([513, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([514])) that is different to the input size (torch.Size([514, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([515])) that is different to the input size (torch.Size([515, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([517])) that is different to the input size (torch.Size([517, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([516])) that is different to the input size (torch.Size([516, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([192])) that is different to the input size (torch.Size([192, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 258/258 [00:04<00:00, 53.87it/s]\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([191])) that is different to the input size (torch.Size([191, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 258/258 [00:04<00:00, 59.76it/s]\n",
      "100%|██████████| 258/258 [00:04<00:00, 63.52it/s]\n",
      "100%|██████████| 258/258 [00:04<00:00, 55.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# MODEL TRAINING\n",
    "print(\"Training started, progress available in Tensorboard\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%Hh%Mm\")\n",
    "model_path_base = (\n",
    "    f\"{cs_ofg_config['model_output_path']}/{str(model).split('(')[0]}_{timestamp}\"\n",
    ")\n",
    "\n",
    "best_state_dict_path = hetero_training_utils.run_training_hetero(\n",
    "    target_node_type=cs_ofg_config[\"target_node_type\"],\n",
    "    num_epochs=cs_ofg_config[\"EPOCHS\"],\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    optimizer=cs_ofg_config[\"optimizer\"](\n",
    "        model.parameters(), **cs_ofg_config[\"optimizer_settings\"]\n",
    "    ),\n",
    "    loss_fn=cs_ofg_config[\"loss_fn\"],\n",
    "    early_stopping_criterion=cs_ofg_config[\"early_stopping\"],\n",
    "    model_path_base=model_path_base,\n",
    "    device=cs_ofg_config[\"device\"],\n",
    "    verbose=cs_ofg_config[\"verbose\"],\n",
    ")\n",
    "\n",
    "# Write experiment settings as JSON into model path (of the model we've just trained)\n",
    "with open(os.path.join(model_path_base, \"experiment_settings.json\"), \"w\") as file_path:\n",
    "    json.dump(evaluation_utils.get_json_serializable_dict(cs_ofg_config), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "models/CS/ofg/GraphModule_20230729_20h15m\n",
      "{'Test L1Loss()': tensor(0.4708, device='cuda:0', dtype=torch.float64),\n",
      " 'Train L1Loss()': tensor(0.4665, device='cuda:0', dtype=torch.float64),\n",
      " 'Val L1Loss()': tensor(0.4687, device='cuda:0', dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "state_dict_path = f\"{cs_ofg_config['model_output_path']}/GraphModule_20230728_10h57m/state_dict_epoch0.pt\"  # 0.4708 test mae | HeteroHigherOrderGNN(64, 1) | 36k params\n",
    "state_dict_path = f\"{cs_ofg_config['model_output_path']}/GraphModule_20230728_11h47m/state_dict_epoch0.pt\"  # 0.4663 test mae | HeteroHigherOrderGNN(32, 1) | 14k params\n",
    "state_dict_path = f\"{cs_ofg_config['model_output_path']}/GraphModule_20230729_17h54m/state_dict_epoch0.pt\"  # 0.4689 test mae | HeteroHigherOrderGNN(32, 1) | 21k params\n",
    "state_dict_path = f\"{cs_ofg_config['model_output_path']}/GraphModule_20230729_18h17m/state_dict_epoch1.pt\"  # 0.4607 test mae | HeteroHigherOrderGNN(32, 1) | 21k params\n",
    "\n",
    "\n",
    "# Get MAE results\n",
    "evaluation_dict = hetero_evaluation_utils.evaluate_best_model(\n",
    "    target_node_type=cs_ofg_config[\"target_node_type\"],\n",
    "    model_state_dict_path=best_state_dict_path,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    model=model,\n",
    "    metric=torch.nn.L1Loss(),\n",
    "    device=cs_ofg_config[\"device\"],\n",
    "    verbose=cs_ofg_config[\"verbose\"],\n",
    ")\n",
    "\n",
    "# Store model results as JSON into model path\n",
    "with open(os.path.join(model_path_base, \"evaluation_report.json\"), \"w\") as file_path:\n",
    "    json.dump(evaluation_utils.get_json_serializable_dict(evaluation_dict), file_path)\n",
    "\n",
    "# Print MAE results\n",
    "print()\n",
    "print(model_path_base)\n",
    "pprint.pprint(evaluation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
