{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "go_up_n_directories = lambda path, n: os.path.abspath(\n",
    "    os.path.join(*([os.path.dirname(path)] + [\"..\"] * n))\n",
    ")\n",
    "try:\n",
    "    suda=suda # will give an error if this cell has not run before\n",
    "except:\n",
    "    os.chdir(go_up_n_directories(os.getcwd(), 3))  # run once (otherwise restart kernel)\n",
    "    suda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz (4x)\n",
      "Total CPU memory: 46.93GB\n",
      "Available CPU memory: 42.77GB\n",
      "GPU: NVIDIA GeForce GTX 960\n",
      "Total GPU memory: 4096.0MB\n",
      "Available GPU memory: 4029.0MB\n",
      "Platform: Linux-6.2.0-32-generic-x86_64-with-glibc2.35\n",
      "Torch version: 1.13.1+cu117\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# DEPENDENCIES\n",
    "# Python native\n",
    "import functools\n",
    "\n",
    "# Data handling\n",
    "import ocpa.algo.predictive_monitoring.factory as feature_factory\n",
    "\n",
    "# PyG\n",
    "import torch\n",
    "import torch.optim as O\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "import utilities.torch_utils\n",
    "\n",
    "# Custom imports\n",
    "from models.definitions.geometric_models import HigherOrderGNN\n",
    "from utilities import hetero_data_utils, hetero_experiment_utils\n",
    "\n",
    "# Print system info\n",
    "utilities.torch_utils.print_system_info()\n",
    "utilities.torch_utils.print_torch_info()\n",
    "\n",
    "# INITIAL CONFIGURATION\n",
    "bpi17_hoeg_config = {\n",
    "    \"model_output_path\": \"models/BPI17/hoeg\",\n",
    "    \"STORAGE_PATH\": \"data/BPI17/feature_encodings/HOEG/hoeg\",\n",
    "    \"SPLIT_FEATURE_STORAGE_FILE\": \"BPI_split_[C2_P2_P3_P5_O3_Action_EventOrigin_OrgResource].fs\",\n",
    "    \"OBJECTS_DATA_DICT\": \"bpi17_ofg+oi_graph+app_node_map+off_node_map.pkl\",\n",
    "    \"events_target_label\": (feature_factory.EVENT_REMAINING_TIME, ()),\n",
    "    \"objects_target_label\": \"@@object_lifecycle_duration\",\n",
    "    \"graph_level_target\": False,\n",
    "    \"target_node_type\": \"event\",\n",
    "    \"object_types\": [\"application\", \"offer\"],\n",
    "    \"meta_data\": (\n",
    "        [\"event\", \"application\", \"offer\"],\n",
    "        [\n",
    "            (\"event\", \"follows\", \"event\"),\n",
    "            (\"application\", \"interacts\", \"event\"),\n",
    "            (\"offer\", \"interacts\", \"event\"),\n",
    "        ],\n",
    "    ),\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    \"RANDOM_SEED\": 42,\n",
    "    \"EPOCHS\": 30,\n",
    "    \"early_stopping\": 4,\n",
    "    \"hidden_dim\": 32,\n",
    "    \"optimizer\": O.Adam,\n",
    "    \"optimizer_settings\": {\n",
    "        \"lr\": 0.001,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-08,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": False,\n",
    "    },\n",
    "    \"loss_fn\": torch.nn.L1Loss(),\n",
    "    \"verbose\": True,\n",
    "    \"skip_cache\": False,\n",
    "    \"track_time\": True,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"squeeze\": True,\n",
    "}\n",
    "\n",
    "# CONFIGURATION ADAPTATIONS may be set here\n",
    "# bpi17_hoeg_config[\"EPOCHS\"] = 1\n",
    "# bpi17_hoeg_config[\"early_stopping\"] = 4\n",
    "# bpi17_hoeg_config[\"skip_cache\"] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION\n",
    "transformations = [\n",
    "    # hetero_data_utils.ToUndirected(\n",
    "    #     exclude_edge_types=[(\"event\", \"follows\", \"event\")]\n",
    "    # ),  # Convert heterogeneous graphs to undirected graphs, but exclude event-event relations\n",
    "    # T.ToUndirected(),  # Convert the graph to an undirected graph   # this was in HOEG.py in v0.18\n",
    "    hetero_data_utils.AddObjectSelfLoops(),  # Prepares object-object relations, which are filled when `T.AddSelfLoops()` is executed\n",
    "    T.AddSelfLoops(),  # Add self-loops to the graph                # this was in HOEG.py in v0.18\n",
    "    T.NormalizeFeatures(),  # Normalize node features of the graph  # this was in HOEG.py in v0.18\n",
    "]\n",
    "# Get data and dataloaders\n",
    "ds_train, ds_val, ds_test = hetero_data_utils.load_hetero_datasets(\n",
    "    bpi17_hoeg_config[\"STORAGE_PATH\"],\n",
    "    bpi17_hoeg_config[\"SPLIT_FEATURE_STORAGE_FILE\"],\n",
    "    bpi17_hoeg_config[\"OBJECTS_DATA_DICT\"],\n",
    "    event_node_label_key=bpi17_hoeg_config[\"events_target_label\"],\n",
    "    object_nodes_label_key=bpi17_hoeg_config[\"objects_target_label\"],\n",
    "    edge_types=bpi17_hoeg_config[\"meta_data\"][1],\n",
    "    object_node_types=bpi17_hoeg_config[\"object_types\"],\n",
    "    graph_level_target=False,\n",
    "    transform=T.Compose(transformations),\n",
    "    train=True,\n",
    "    val=True,\n",
    "    test=True,\n",
    "    skip_cache=bpi17_hoeg_config[\"skip_cache\"],\n",
    ")\n",
    "for data in ds_val:\n",
    "    if data.metadata() != bpi17_hoeg_config[\"meta_data\"]:\n",
    "        bpi17_hoeg_config[\"meta_data\"] = data.metadata()\n",
    "        break\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    ") = hetero_data_utils.hetero_dataloaders_from_datasets(\n",
    "    batch_size=bpi17_hoeg_config[\"BATCH_SIZE\"],\n",
    "    ds_train=ds_train,\n",
    "    ds_val=ds_val,\n",
    "    ds_test=ds_test,\n",
    "    num_workers=3,\n",
    "    seed_worker=functools.partial(\n",
    "        utilities.torch_utils.seed_worker, state=bpi17_hoeg_config[\"RANDOM_SEED\"]\n",
    "    ),\n",
    "    generator=torch.Generator().manual_seed(bpi17_hoeg_config[\"RANDOM_SEED\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr=0.01, hidden_dim=8:\n",
      "Training started, progress available in Tensorboard\n",
      "EPOCH 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:379: UserWarning: 'acts.0' will be duplicated, but its parameters cannot be reset. To suppress this warning, add a 'reset_parameters()' method to 'acts.0'\n",
      "  warnings.warn(\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:379: UserWarning: 'acts.1' will be duplicated, but its parameters cannot be reset. To suppress this warning, add a 'reset_parameters()' method to 'acts.1'\n",
      "  warnings.warn(\n",
      "100it [00:03, 34.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 100 loss: 0.7083802169561386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110it [00:03, 29.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m lr \u001b[39min\u001b[39;00m lr_range:\n\u001b[1;32m     12\u001b[0m     \u001b[39mfor\u001b[39;00m hidden_dim \u001b[39min\u001b[39;00m hidden_dim_range:\n\u001b[0;32m---> 13\u001b[0m         hetero_experiment_utils\u001b[39m.\u001b[39;49mrun_hoeg_experiment_configuration(\n\u001b[1;32m     14\u001b[0m             HigherOrderGNN,\n\u001b[1;32m     15\u001b[0m             lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m     16\u001b[0m             hidden_dim\u001b[39m=\u001b[39;49mhidden_dim,\n\u001b[1;32m     17\u001b[0m             train_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m     18\u001b[0m             val_loader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     19\u001b[0m             test_loader\u001b[39m=\u001b[39;49mtest_loader,\n\u001b[1;32m     20\u001b[0m             hoeg_config\u001b[39m=\u001b[39;49mbpi17_hoeg_config,\n\u001b[1;32m     21\u001b[0m         )\n",
      "File \u001b[0;32m~/Development/OCPPM/utilities/hetero_experiment_utils.py:54\u001b[0m, in \u001b[0;36mrun_hoeg_experiment_configuration\u001b[0;34m(model_class, lr, hidden_dim, train_loader, val_loader, test_loader, hoeg_config)\u001b[0m\n\u001b[1;32m     51\u001b[0m timestamp \u001b[39m=\u001b[39m start_train_time\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mHh\u001b[39m\u001b[39m%\u001b[39m\u001b[39mMm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m model_path_base \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mhoeg_config[\u001b[39m'\u001b[39m\u001b[39mmodel_output_path\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/lr=\u001b[39m\u001b[39m{\u001b[39;00mhoeg_config[\u001b[39m'\u001b[39m\u001b[39moptimizer_settings\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_hidden_dim=\u001b[39m\u001b[39m{\u001b[39;00mhoeg_config[\u001b[39m'\u001b[39m\u001b[39mhidden_dim\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(model)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m best_state_dict_path \u001b[39m=\u001b[39m hetero_training_utils\u001b[39m.\u001b[39;49mrun_training_hetero(\n\u001b[1;32m     55\u001b[0m     target_node_type\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39mtarget_node_type\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     56\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39mEPOCHS\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     57\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     58\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m     59\u001b[0m     validation_loader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     60\u001b[0m     optimizer\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39moptimizer\u001b[39;49m\u001b[39m\"\u001b[39;49m](\n\u001b[1;32m     61\u001b[0m         model\u001b[39m.\u001b[39;49mparameters(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39moptimizer_settings\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     62\u001b[0m     ),\n\u001b[1;32m     63\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39mloss_fn\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     64\u001b[0m     early_stopping_criterion\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39mearly_stopping\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     65\u001b[0m     model_path_base\u001b[39m=\u001b[39;49mmodel_path_base,\n\u001b[1;32m     66\u001b[0m     device\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39mdevice\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     67\u001b[0m     verbose\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     68\u001b[0m     squeeze_required\u001b[39m=\u001b[39;49mhoeg_config[\u001b[39m\"\u001b[39;49m\u001b[39msqueeze\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     70\u001b[0m total_train_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_train_time\n\u001b[1;32m     72\u001b[0m \u001b[39m# Write experiment settings as JSON into model path (of the model we've just trained)\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/OCPPM/utilities/hetero_training_utils.py:107\u001b[0m, in \u001b[0;36mrun_training_hetero\u001b[0;34m(target_node_type, num_epochs, model, train_loader, validation_loader, optimizer, loss_fn, early_stopping_criterion, device, model_path_base, verbose, squeeze_required)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m    105\u001b[0m     \u001b[39m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 107\u001b[0m     avg_loss \u001b[39m=\u001b[39m train_one_epoch_hetero(\n\u001b[1;32m    108\u001b[0m         target_node_type,\n\u001b[1;32m    109\u001b[0m         epoch,\n\u001b[1;32m    110\u001b[0m         model,\n\u001b[1;32m    111\u001b[0m         train_loader,\n\u001b[1;32m    112\u001b[0m         optimizer,\n\u001b[1;32m    113\u001b[0m         loss_fn,\n\u001b[1;32m    114\u001b[0m         writer,\n\u001b[1;32m    115\u001b[0m         device,\n\u001b[1;32m    116\u001b[0m         verbose,\n\u001b[1;32m    117\u001b[0m         squeeze_required,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     \u001b[39m# We don't need gradients on to do reporting\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Development/OCPPM/utilities/hetero_training_utils.py:53\u001b[0m, in \u001b[0;36mtrain_one_epoch_hetero\u001b[0;34m(target_node_type, epoch_index, model, train_loader, optimizer, loss_fn, tb_writer, device, verbose, squeeze_required)\u001b[0m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m \u001b[39m# Passing the node features and the connection info\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m     54\u001b[0m     inputs, edge_index\u001b[39m=\u001b[39;49madjacency_matrix  \u001b[39m# , batch=batch[target_node_type].batch\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39m# Compute loss and gradients\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m squeeze_required:\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch/fx/graph_module.py:658\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_wrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_call(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch/fx/graph_module.py:267\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_call(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    266\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcls, obj)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m     \u001b[39massert\u001b[39;00m e\u001b[39m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.1:17\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m convs_0__event1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mevent__follows__event(x__event, edge_index__event__follows__event)\n\u001b[1;32m     16\u001b[0m convs_0__event2 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mapplication__interacts__event((x__application, x__event), edge_index__application__interacts__event)\n\u001b[0;32m---> 17\u001b[0m convs_0__event3 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs, \u001b[39m\"\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49moffer__interacts__event((x__offer, x__event), edge_index__offer__interacts__event);  x__event \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m convs_0__application \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mapplication__updates__application(x__application, edge_index__application__updates__application);  x__application \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m convs_0__offer \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39moffer__updates__offer(x__offer, edge_index__offer__updates__offer);  x__offer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch_geometric/nn/conv/graph_conv.py:92\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     90\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m x_r \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin_root(x_r)\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch_geometric/nn/dense/linear.py:132\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Just some trials\n",
    "bpi17_hoeg_config[\"verbose\"] = False\n",
    "bpi17_hoeg_config[\"model_output_path\"] = \"models/BPI17/hoeg/exp_ss\"\n",
    "\n",
    "\n",
    "hetero_experiment_utils.run_hoeg_experiment_configuration(\n",
    "    HigherOrderGNN,\n",
    "    lr=0.001,\n",
    "    hidden_dim=32,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    hoeg_config=bpi17_hoeg_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
