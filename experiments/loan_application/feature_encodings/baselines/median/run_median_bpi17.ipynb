{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tim/Development/OCPPM'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "go_up_n_directories = lambda path, n: os.path.abspath(\n",
    "    os.path.join(*([os.path.dirname(path)] + [\"..\"] * n))\n",
    ")\n",
    "os.chdir(go_up_n_directories(os.getcwd(), 4))  # run once (otherwise restart kernel)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python natives\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from utilities import evaluation_utils\n",
    "from ocpa.algo.predictive_monitoring.obj import Feature_Storage\n",
    "from ocpa.algo.predictive_monitoring import tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_storage_file = \"data/BPI17/feature_encodings/EFG/efg/raw/BPI_split_[C2_P2_P3_P5_O3_Action_EventOrigin_OrgResource].fs\"\n",
    "target = (\"event_remaining_time\", ())\n",
    "model_output_path = \"models/BPI17/baselines/median\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(feature_storage_file, \"rb\") as bin:\n",
    "    feature_storage: Feature_Storage = pickle.load(bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten EFG with same train/test split\n",
    "eft_train = tabular.construct_table(\n",
    "    feature_storage, feature_storage.train_indices + feature_storage.validation_indices\n",
    ")\n",
    "eft_test = tabular.construct_table(feature_storage, feature_storage.test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset relevant data\n",
    "y_train = eft_train[target]\n",
    "y_test = eft_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = time.time()\n",
    "# fit the model ;)\n",
    "median = y_train.median()\n",
    "total_train_time = time.time() - train_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_start_time = time.time()\n",
    "y_train_preds = [median] * y_train.shape[0]\n",
    "train_pred_time = time.time() - pred_start_time\n",
    "\n",
    "pred_start_time = time.time()\n",
    "y_test_preds = [median] * y_test.shape[0]\n",
    "test_pred_time = time.time() - pred_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_train = evaluation_utils.get_evaluation(\n",
    "    y_train, y_train_preds, regression=True, time=train_pred_time\n",
    ")\n",
    "eval_train[\"report\"][\"training_time\"] = total_train_time\n",
    "eval_valid = evaluation_utils.get_evaluation(\n",
    "    y_test, y_test_preds, regression=True, time=test_pred_time\n",
    ")\n",
    "evaluation_report = {\"Train\": eval_train, \"Test\": eval_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Test': {'report': {'MAE': 0.7746246264487259,\n",
      "                     'MAPE': 4.717113662945489,\n",
      "                     'MSE': 1.047181432735379,\n",
      "                     'R^2': -0.06980023131687063,\n",
      "                     'prediction_time': 0.00015997886657714844}},\n",
      " 'Train': {'report': {'MAE': 0.7854286288089017,\n",
      "                      'MAPE': 4.976396720117326,\n",
      "                      'MSE': 1.0802058186052832,\n",
      "                      'R^2': -0.07491865804165632,\n",
      "                      'prediction_time': 0.00029540061950683594,\n",
      "                      'training_time': 0.004192829132080078}}}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(model_output_path, \"evaluation_report.json\"), \"w\") as fp:\n",
    "    json.dump(evaluation_report, fp, indent=2)\n",
    "\n",
    "pprint.pprint(evaluation_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
