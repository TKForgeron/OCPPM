{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "go_up_n_directories = lambda path, n: os.path.abspath(\n",
    "    os.path.join(*([os.path.dirname(path)] + [\"..\"] * n))\n",
    ")\n",
    "try:\n",
    "    suda=suda # will give an error if this cell has not run before\n",
    "except:\n",
    "    os.chdir(go_up_n_directories(os.getcwd(), 3))  # run once (otherwise restart kernel)\n",
    "    suda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz (4x)\n",
      "Total CPU memory: 46.93GB\n",
      "Available CPU memory: 32.55GB\n",
      "GPU: NVIDIA GeForce GTX 960\n",
      "Total GPU memory: 4096.0MB\n",
      "Available GPU memory: 3128.0MB\n",
      "Platform: Linux-6.2.0-26-generic-x86_64-with-glibc2.35\n"
     ]
    }
   ],
   "source": [
    "# DEPENDENCIES\n",
    "# Python native\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "import functools\n",
    "import json\n",
    "import time\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from statistics import median as median\n",
    "from sys import platform\n",
    "from typing import Any, Callable\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import ocpa.algo.predictive_monitoring.factory as feature_factory\n",
    "\n",
    "# PyG\n",
    "import torch\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "import torch.utils.tensorboard\n",
    "\n",
    "# Object centric process mining\n",
    "from ocpa.algo.predictive_monitoring.obj import Feature_Storage as FeatureStorage\n",
    "\n",
    "# # Simple machine learning models, procedure tools, and evaluation metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from tqdm import tqdm\n",
    "from torch import tensor\n",
    "\n",
    "# Custom imports\n",
    "from experiments.efg import EFG\n",
    "from experiments.efg_sg import EFG_SG\n",
    "from utilities import (\n",
    "    data_utils,\n",
    "    evaluation_utils,\n",
    "    experiment_utils,\n",
    "    training_utils,\n",
    ")\n",
    "import utilities.torch_utils\n",
    "\n",
    "# from importing_ocel import build_feature_storage, load_ocel, pickle_feature_storage\n",
    "from models.definitions.geometric_models import (\n",
    "    AGNN_EFG,\n",
    "    AdamsGCN,\n",
    "    GraphModel,\n",
    "    HigherOrderGNN,\n",
    "    SimpleGNN_EFG,\n",
    ")\n",
    "import torch_geometric.nn as pygnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "\n",
    "# Print system info\n",
    "utilities.torch_utils.print_system_info()\n",
    "\n",
    "# Setup\n",
    "bpi17_efg_config = {\n",
    "    \"model_output_path\": \"models/BPI17/efg\",\n",
    "    \"STORAGE_PATH\": \"data/BPI17/feature_encodings/EFG/efg\",\n",
    "    \"SPLIT_FEATURE_STORAGE_FILE\": \"BPI_split_[C2_P2_P3_P5_O3_Action_EventOrigin_OrgResource].fs\",\n",
    "    \"TARGET_LABEL\": (feature_factory.EVENT_REMAINING_TIME, ()),\n",
    "    \"regression_task\": True,\n",
    "    \"graph_level_prediction\": False,\n",
    "    \"dataset_class\": EFG,\n",
    "    \"features_dtype\": torch.float32,\n",
    "    \"target_dtype\": torch.float32,\n",
    "    \"SUBGRAPH_SIZE\": 4,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"RANDOM_SEED\": 42,\n",
    "    \"EPOCHS\": 30,\n",
    "    \"early_stopping\": 4,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"optimizer\": O.Adam,\n",
    "    \"optimizer_settings\": {\n",
    "        \"lr\": 0.001,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-08,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": False,\n",
    "    },\n",
    "    \"loss_fn\": torch.nn.L1Loss(),\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"verbose\": True,\n",
    "    \"track_time\": True,\n",
    "    \"skip_cache\": False,\n",
    "    \"squeeze\": True,\n",
    "}\n",
    "\n",
    "# ADAPTATIONS\n",
    "bpi17_efg_config[\"skip_cache\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "17645it [00:06, 2836.73it/s]\n",
      "Done!\n",
      "Processing...\n",
      "4411it [00:01, 2727.10it/s]\n",
      "Done!\n",
      "Processing...\n",
      "9453it [00:03, 2519.64it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get data and dataloaders\n",
    "ds_train, ds_val, ds_test = data_utils.load_datasets(\n",
    "    dataset_class=bpi17_efg_config[\"dataset_class\"],\n",
    "    storage_path=bpi17_efg_config[\"STORAGE_PATH\"],\n",
    "    split_feature_storage_file=bpi17_efg_config[\"SPLIT_FEATURE_STORAGE_FILE\"],\n",
    "    target_label=bpi17_efg_config[\"TARGET_LABEL\"],\n",
    "    graph_level_target=bpi17_efg_config[\"graph_level_prediction\"],\n",
    "    features_dtype=bpi17_efg_config[\"features_dtype\"],\n",
    "    target_dtype=bpi17_efg_config[\"target_dtype\"],\n",
    "    subgraph_size=bpi17_efg_config[\"SUBGRAPH_SIZE\"],\n",
    "    train=True,\n",
    "    val=True,\n",
    "    test=True,\n",
    "    skip_cache=bpi17_efg_config[\"skip_cache\"],\n",
    ")\n",
    "train_loader, val_loader, test_loader = data_utils.prepare_dataloaders(\n",
    "    batch_size=bpi17_efg_config[\"BATCH_SIZE\"],\n",
    "    ds_train=ds_train,\n",
    "    ds_val=ds_val,\n",
    "    ds_test=ds_test,\n",
    "    num_workers=3,\n",
    "    seed_worker=functools.partial(\n",
    "        utilities.torch_utils.seed_worker, state=bpi17_efg_config[\"RANDOM_SEED\"]\n",
    "    ),\n",
    "    generator=torch.Generator().manual_seed(bpi17_efg_config[\"RANDOM_SEED\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HigherOrderGNN(\n",
      "  (bn1): BatchNorm(16)\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphConv(-1, 16)\n",
      "    (1): GraphConv(16, 16)\n",
      "    (2): GraphConv(16, 16)\n",
      "    (3): GraphConv(16, 16)\n",
      "  )\n",
      "  (acts): ModuleList(\n",
      "    (0): SELU()\n",
      "    (1): SELU()\n",
      "    (2): SELU()\n",
      "  )\n",
      "  (lin_out): Linear(-1, 1, bias=True)\n",
      ")\n",
      "Number of parameters: 2513\n"
     ]
    }
   ],
   "source": [
    "# # MODEL INITIALIZATION\n",
    "class HigherOrderGNN(GraphModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int = 48,\n",
    "        out_channels: int = 1,\n",
    "        no_mp_layers: int = 4,\n",
    "        regression_target: bool = True,\n",
    "        graph_level_prediction: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bn1 = pygnn.BatchNorm(hidden_channels)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(pygnn.GraphConv(-1, hidden_channels))\n",
    "        self.acts = nn.ModuleList()\n",
    "        for i in range(no_mp_layers - 1):\n",
    "            self.convs.append(pygnn.GraphConv(hidden_channels, hidden_channels))\n",
    "            self.acts.append(nn.PReLU())\n",
    "        self.lin_out = pygnn.Linear(-1, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        for conv, act in zip(self.convs, self.acts):\n",
    "            x = conv(x, edge_index)\n",
    "            x = act(x)\n",
    "        x = self.lin_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = HigherOrderGNN(16, 1)\n",
    "# # pretrained_state_dict = torch.load(\"models/runs/GraphConvNet_20230718_13h59m/state_dict_epoch6.pt\")\n",
    "# # model.load_state_dict(pretrained_state_dict)\n",
    "\n",
    "# Print summary of data and model\n",
    "if bpi17_efg_config[\"verbose\"]:\n",
    "    print(model)\n",
    "    with torch.no_grad():  # Initialize lazy modules, s.t. we can count its parameters.\n",
    "        batch = next(iter(train_loader))\n",
    "        batch.to(bpi17_efg_config[\"device\"])\n",
    "        model.to(bpi17_efg_config[\"device\"])\n",
    "        out = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "        print(f\"Number of parameters: {utilities.torch_utils.count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr=0.01, hidden_dim=32:\n",
      "Training started, progress available in Tensorboard\n",
      "EPOCH 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 87.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5377864241600037\n",
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 87.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5356507301330566\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 84.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5341624617576599\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 80.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5305600762367249\n",
      "EPOCH 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:02, 96.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5256773829460144\n",
      "EPOCH 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:02, 98.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5379061102867126\n",
      "EPOCH 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 90.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5234783291816711\n",
      "EPOCH 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 74.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5253446698188782\n",
      "EPOCH 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:04, 62.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5244303941726685\n",
      "EPOCH 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:02, 107.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.523101270198822\n",
      "EPOCH 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:02, 99.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5330312252044678\n",
      "EPOCH 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 89.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5281625390052795\n",
      "EPOCH 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:02, 95.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.535510778427124\n",
      "EPOCH 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:02, 107.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss -> train: 0 valid: 0.5271446108818054\n",
      "Early stopping after 14 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [00:11<00:00, 24.18it/s]\n",
      "100%|██████████| 69/69 [00:08<00:00,  8.36it/s]\n",
      "100%|██████████| 148/148 [00:16<00:00,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.01, hidden_dim=32:\n",
      "    8097 parameters\n",
      "    0:00:57.702201 H:m:s\n",
      "    0.5073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bpi17_efg_config[\"model_output_path\"] = \"models/BPI17/efg/no_subgraph_sampling\"\n",
    "\n",
    "experiment_utils.run_efg_experiment_configuration(\n",
    "    model_class=HigherOrderGNN,\n",
    "    lr=0.01,\n",
    "    hidden_dim=32,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    efg_config=bpi17_efg_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 18 epochs.\n",
      "lr=0.01, hidden_dim=8:\n",
      "    587 parameters\n",
      "    0:11:19.402490 H:m:s\n",
      "    0.4284\n",
      "\n",
      "Early stopping after 6 epochs.\n",
      "lr=0.01, hidden_dim=16:\n",
      "    1427 parameters\n",
      "    0:03:57.227688 H:m:s\n",
      "    0.4321\n",
      "\n",
      "Early stopping after 10 epochs.\n",
      "lr=0.01, hidden_dim=24:\n",
      "    2523 parameters\n",
      "    0:06:36.402405 H:m:s\n",
      "    0.4238\n",
      "\n",
      "Early stopping after 15 epochs.\n",
      "lr=0.01, hidden_dim=32:\n",
      "    3875 parameters\n",
      "    0:10:18.807842 H:m:s\n",
      "    0.4219\n",
      "\n",
      "Early stopping after 14 epochs.\n",
      "lr=0.01, hidden_dim=48:\n",
      "    7347 parameters\n",
      "    0:09:24.318881 H:m:s\n",
      "    0.4240\n",
      "\n",
      "Early stopping after 8 epochs.\n",
      "lr=0.01, hidden_dim=64:\n",
      "    11843 parameters\n",
      "    0:05:14.845230 H:m:s\n",
      "    0.4272\n",
      "\n",
      "Early stopping after 13 epochs.\n",
      "lr=0.01, hidden_dim=128:\n",
      "    40067 parameters\n",
      "    0:09:49.965929 H:m:s\n",
      "    0.4287\n",
      "\n",
      "Early stopping after 6 epochs.\n",
      "lr=0.01, hidden_dim=256:\n",
      "    145667 parameters\n",
      "    0:04:15.462002 H:m:s\n",
      "    0.4461\n",
      "\n",
      "Early stopping after 27 epochs.\n",
      "lr=0.001, hidden_dim=8:\n",
      "    587 parameters\n",
      "    0:21:30.648002 H:m:s\n",
      "    0.4303\n",
      "\n",
      "lr=0.001, hidden_dim=16:\n",
      "    1427 parameters\n",
      "    0:18:29.603920 H:m:s\n",
      "    0.4149\n",
      "\n",
      "lr=0.001, hidden_dim=24:\n",
      "    2523 parameters\n",
      "    0:18:06.767217 H:m:s\n",
      "    0.4135\n",
      "\n",
      "Early stopping after 15 epochs.\n",
      "lr=0.001, hidden_dim=32:\n",
      "    3875 parameters\n",
      "    0:10:35.929280 H:m:s\n",
      "    0.4142\n",
      "\n",
      "Early stopping after 26 epochs.\n",
      "lr=0.001, hidden_dim=48:\n",
      "    7347 parameters\n",
      "    0:17:56.468000 H:m:s\n",
      "    0.4075\n",
      "\n",
      "Early stopping after 30 epochs.\n",
      "lr=0.001, hidden_dim=64:\n",
      "    11843 parameters\n",
      "    0:20:11.086467 H:m:s\n",
      "    0.4064\n",
      "\n",
      "Early stopping after 24 epochs.\n",
      "lr=0.001, hidden_dim=128:\n",
      "    40067 parameters\n",
      "    0:17:06.949516 H:m:s\n",
      "    0.4076\n",
      "\n",
      "Early stopping after 14 epochs.\n",
      "lr=0.001, hidden_dim=256:\n",
      "    145667 parameters\n",
      "    0:11:27.485126 H:m:s\n",
      "    0.4101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_range = [0.01, 0.001]\n",
    "hidden_dim_range = [8, 16, 24, 32, 48, 64, 128, 256]\n",
    "for lr in lr_range:\n",
    "    for hidden_dim in hidden_dim_range:\n",
    "        experiment_utils.run_efg_experiment_configuration(\n",
    "            model_class=HigherOrderGNN_EFG,\n",
    "            lr=lr,\n",
    "            hidden_dim=hidden_dim,\n",
    "            track_time=True,\n",
    "            verbose=False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
