{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python native\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/tim/Development/OCPPM/\")\n",
    "import pickle\n",
    "import random\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from statistics import median as median\n",
    "from sys import platform\n",
    "from typing import Any, Callable\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ocpa.algo.predictive_monitoring.factory as feature_factory\n",
    "\n",
    "# PyG\n",
    "import torch\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "import torch.utils.tensorboard\n",
    "\n",
    "# Object centric process mining\n",
    "from ocpa.algo.predictive_monitoring.obj import Feature_Storage as FeatureStorage\n",
    "\n",
    "# # Simple machine learning models, procedure tools, and evaluation metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom imports\n",
    "# from loan_application_experiment.feature_encodings.efg.efg import EFG\n",
    "from loan_application_experiment.feature_encodings.efg.efg_sg import EFG_SG\n",
    "\n",
    "# from importing_ocel import build_feature_storage, load_ocel, pickle_feature_storage\n",
    "from loan_application_experiment.models.geometric_models import AdamsGCN, GraphModel, AGNN\n",
    "from test_gnn_on_efg_sg import evaluate_best_model, load_datasets, prepare_dataloaders, configure_adams_model,print_dataset_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_path = \"models/runs/AGNN_20230713_21h55m\"\n",
    "\n",
    "bpi17_config = {\n",
    "    \"STORAGE_PATH\": \"data/BPI17/feature_encodings/EFG/efg\",\n",
    "    \"SPLIT_FEATURE_STORAGE_FILE\": \"BPI_split_[C2_P2_P3_P5_O3_Action_EventOrigin_OrgResource].fs\",\n",
    "    \"TARGET_LABEL\": (feature_factory.EVENT_REMAINING_TIME, ()),\n",
    "    \"SUBGRAPH_SIZE\": 4,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"RANDOM_SEED\": 42,\n",
    "    \"EPOCHS\": 30,\n",
    "    \"early_stopping\": 7,\n",
    "    \"optimizer_settings\": {\n",
    "        \"lr\": 0.001,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-08,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": False,\n",
    "    },\n",
    "    \"loss_fn\": torch.nn.L1Loss(),\n",
    "    \"verbose\": True,\n",
    "    \"skip_cache\": False,\n",
    "}\n",
    "\n",
    "\n",
    "def seed_worker(worker_id: int) -> None:\n",
    "    # worker_seed = torch.initial_seed() % RANDOM_SEED\n",
    "    worker_seed = bpi17_config[\"RANDOM_SEED\"]\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "generator = torch.Generator().manual_seed(bpi17_config[\"RANDOM_SEED\"])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and dataloaders\n",
    "ds_train, ds_val, ds_test = load_datasets(\n",
    "    bpi17_config[\"STORAGE_PATH\"],\n",
    "    bpi17_config[\"SPLIT_FEATURE_STORAGE_FILE\"],\n",
    "    bpi17_config[\"TARGET_LABEL\"],\n",
    "    bpi17_config[\"SUBGRAPH_SIZE\"],\n",
    "    train=True,\n",
    "    val=True,\n",
    "    test=True,\n",
    ")\n",
    "# print_dataset_summaries(ds_train, ds_val, ds_test)\n",
    "train_loader, val_loader, test_loader = prepare_dataloaders(\n",
    "    batch_size=bpi17_config[\"BATCH_SIZE\"],\n",
    "    ds_train=ds_train,\n",
    "    ds_val=ds_val,\n",
    "    ds_test=ds_test,\n",
    "    seed_worker=seed_worker,\n",
    "    generator=generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AGNN:\n\tMissing key(s) in state_dict: \"conv1.att\", \"conv1.bias\", \"conv1.lin_l.weight\", \"conv1.lin_l.bias\", \"conv1.lin_r.weight\", \"conv1.lin_r.bias\", \"conv2.att\", \"conv2.bias\", \"conv2.lin_l.weight\", \"conv2.lin_l.bias\", \"conv2.lin_r.weight\", \"conv2.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.lin_msg.weight\", \"conv1.lin_msg.bias\", \"conv1.lin_self.weight\", \"conv1.lin_self.bias\", \"conv2.lin_msg.weight\", \"conv2.lin_msg.bias\", \"conv2.lin_self.weight\", \"conv2.lin_self.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m just_get_preds \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a, b: (a, b)\n\u001b[0;32m----> 5\u001b[0m normalized_evaluation_dict \u001b[39m=\u001b[39m evaluate_best_model(\n\u001b[1;32m      6\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      7\u001b[0m     model_state_dir\u001b[39m=\u001b[39;49mstate_dict_path,\n\u001b[1;32m      8\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m      9\u001b[0m     val_loader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     10\u001b[0m     test_loader\u001b[39m=\u001b[39;49mtest_loader,\n\u001b[1;32m     11\u001b[0m     metric\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mL1Loss(),\n\u001b[1;32m     12\u001b[0m     device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     13\u001b[0m     verbose\u001b[39m=\u001b[39;49mbpi17_config[\u001b[39m\"\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/Development/OCPPM/test_gnn_on_efg.py:337\u001b[0m, in \u001b[0;36mevaluate_best_model\u001b[0;34m(model_state_dir, train_loader, val_loader, test_loader, model, metric, device, verbose)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mdir\u001b[39m, latest_state_dict_path)\n\u001b[1;32m    333\u001b[0m best_state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\n\u001b[1;32m    334\u001b[0m     find_latest_state_dict(model_state_dir), map_location\u001b[39m=\u001b[39mdevice\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(best_state_dict)\n\u001b[1;32m    338\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    339\u001b[0m evaluation \u001b[39m=\u001b[39m {\n\u001b[1;32m    340\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain \u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: evaluate_model(\n\u001b[1;32m    341\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m     ),\n\u001b[1;32m    361\u001b[0m }\n",
      "File \u001b[0;32m~/Development/OCPPM/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AGNN:\n\tMissing key(s) in state_dict: \"conv1.att\", \"conv1.bias\", \"conv1.lin_l.weight\", \"conv1.lin_l.bias\", \"conv1.lin_r.weight\", \"conv1.lin_r.bias\", \"conv2.att\", \"conv2.bias\", \"conv2.lin_l.weight\", \"conv2.lin_l.bias\", \"conv2.lin_r.weight\", \"conv2.lin_r.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.lin_msg.weight\", \"conv1.lin_msg.bias\", \"conv1.lin_self.weight\", \"conv1.lin_self.bias\", \"conv2.lin_msg.weight\", \"conv2.lin_msg.bias\", \"conv2.lin_self.weight\", \"conv2.lin_self.bias\". "
     ]
    }
   ],
   "source": [
    "# Set model configuration\n",
    "model = AGNN(hidden_channels=128, out_channels=1)\n",
    "model.to(device)\n",
    "just_get_preds = lambda a, b: (a, b)\n",
    "normalized_evaluation_dict = evaluate_best_model(\n",
    "    model=model,\n",
    "    model_state_dir=state_dict_path,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    metric=torch.nn.L1Loss(),\n",
    "    device=torch.device(\"cpu\"),\n",
    "    verbose=bpi17_config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = normalized_evaluation_dict[list(normalized_evaluation_dict.keys())[0]][0]\n",
    "train_preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.00000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.00000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.064036</td>\n",
       "      <td>-0.023751</td>\n",
       "      <td>-0.058362</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.220502</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>-0.107734</td>\n",
       "      <td>0.065532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038242</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>-0.01388</td>\n",
       "      <td>-0.189062</td>\n",
       "      <td>-0.055596</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>175868.53125</td>\n",
       "      <td>135573.343750</td>\n",
       "      <td>8739.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.894721</td>\n",
       "      <td>0.952523</td>\n",
       "      <td>0.641111</td>\n",
       "      <td>1.153635</td>\n",
       "      <td>1.118303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.062570</td>\n",
       "      <td>1.035689</td>\n",
       "      <td>0.435029</td>\n",
       "      <td>1.065598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.823200</td>\n",
       "      <td>0.651811</td>\n",
       "      <td>0.794690</td>\n",
       "      <td>80577.12500</td>\n",
       "      <td>14970.163086</td>\n",
       "      <td>15889.636719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.234576</td>\n",
       "      <td>-0.098432</td>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.525150</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.285884</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.134923</td>\n",
       "      <td>-0.329228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084695</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>-0.01388</td>\n",
       "      <td>-0.709011</td>\n",
       "      <td>-0.162898</td>\n",
       "      <td>-1.161597</td>\n",
       "      <td>31509.00000</td>\n",
       "      <td>114852.000000</td>\n",
       "      <td>557.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.234576</td>\n",
       "      <td>-0.098432</td>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.525150</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.285884</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.134923</td>\n",
       "      <td>-0.329228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084695</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>-0.01388</td>\n",
       "      <td>-0.698642</td>\n",
       "      <td>-0.162898</td>\n",
       "      <td>-0.057565</td>\n",
       "      <td>86364.00000</td>\n",
       "      <td>128226.000000</td>\n",
       "      <td>2521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.234576</td>\n",
       "      <td>-0.098432</td>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.525150</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.285884</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.134923</td>\n",
       "      <td>-0.329228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084695</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>-0.01388</td>\n",
       "      <td>-0.608030</td>\n",
       "      <td>-0.162898</td>\n",
       "      <td>-0.057565</td>\n",
       "      <td>234196.00000</td>\n",
       "      <td>128226.000000</td>\n",
       "      <td>3832.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.234576</td>\n",
       "      <td>-0.098432</td>\n",
       "      <td>-0.294600</td>\n",
       "      <td>1.891142</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.285884</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.134923</td>\n",
       "      <td>-0.329228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084695</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>-0.01388</td>\n",
       "      <td>-0.118018</td>\n",
       "      <td>-0.162898</td>\n",
       "      <td>-0.057565</td>\n",
       "      <td>234196.00000</td>\n",
       "      <td>150853.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.394430</td>\n",
       "      <td>4.263014</td>\n",
       "      <td>10.159348</td>\n",
       "      <td>3.394430</td>\n",
       "      <td>1.891142</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>3.497917</td>\n",
       "      <td>2.508842</td>\n",
       "      <td>6.825533</td>\n",
       "      <td>2.930726</td>\n",
       "      <td>...</td>\n",
       "      <td>11.807139</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>-0.01388</td>\n",
       "      <td>2.441271</td>\n",
       "      <td>7.360688</td>\n",
       "      <td>3.254531</td>\n",
       "      <td>234196.00000</td>\n",
       "      <td>150853.000000</td>\n",
       "      <td>58953.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  256.000000  256.000000  256.000000  256.000000  256.000000  256.000000   \n",
       "mean    -0.064036   -0.023751   -0.058362    0.108887    0.220502   -0.067831   \n",
       "std      0.894721    0.952523    0.641111    1.153635    1.118303    0.000000   \n",
       "min     -0.294600   -0.234576   -0.098432   -0.294600   -0.525150   -0.067831   \n",
       "25%     -0.294600   -0.234576   -0.098432   -0.294600   -0.525150   -0.067831   \n",
       "50%     -0.294600   -0.234576   -0.098432   -0.294600   -0.525150   -0.067831   \n",
       "75%     -0.294600   -0.234576   -0.098432   -0.294600    1.891142   -0.067831   \n",
       "max      3.394430    4.263014   10.159348    3.394430    1.891142   -0.067831   \n",
       "\n",
       "               6           7           8           9   ...          17  \\\n",
       "count  256.000000  256.000000  256.000000  256.000000  ...  256.000000   \n",
       "mean     0.039286    0.033040   -0.107734    0.065532  ...   -0.038242   \n",
       "std      1.062570    1.035689    0.435029    1.065598  ...    0.743240   \n",
       "min     -0.285884   -0.398522   -0.134923   -0.329228  ...   -0.084695   \n",
       "25%     -0.285884   -0.398522   -0.134923   -0.329228  ...   -0.084695   \n",
       "50%     -0.285884   -0.398522   -0.134923   -0.329228  ...   -0.084695   \n",
       "75%     -0.285884   -0.398522   -0.134923   -0.329228  ...   -0.084695   \n",
       "max      3.497917    2.508842    6.825533    2.930726  ...   11.807139   \n",
       "\n",
       "               18          19         20          21          22          23  \\\n",
       "count  256.000000  256.000000  256.00000  256.000000  256.000000  256.000000   \n",
       "mean    -0.024978   -0.003184   -0.01388   -0.189062   -0.055596    0.007124   \n",
       "std      0.000000    0.000000    0.00000    0.823200    0.651811    0.794690   \n",
       "min     -0.024978   -0.003184   -0.01388   -0.709011   -0.162898   -1.161597   \n",
       "25%     -0.024978   -0.003184   -0.01388   -0.698642   -0.162898   -0.057565   \n",
       "50%     -0.024978   -0.003184   -0.01388   -0.608030   -0.162898   -0.057565   \n",
       "75%     -0.024978   -0.003184   -0.01388   -0.118018   -0.162898   -0.057565   \n",
       "max     -0.024978   -0.003184   -0.01388    2.441271    7.360688    3.254531   \n",
       "\n",
       "                 24             25            26  \n",
       "count     256.00000     256.000000    256.000000  \n",
       "mean   175868.53125  135573.343750   8739.429688  \n",
       "std     80577.12500   14970.163086  15889.636719  \n",
       "min     31509.00000  114852.000000    557.000000  \n",
       "25%     86364.00000  128226.000000   2521.000000  \n",
       "50%    234196.00000  128226.000000   3832.000000  \n",
       "75%    234196.00000  150853.000000   5061.000000  \n",
       "max    234196.00000  150853.000000  58953.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0=next(iter(train_loader))\n",
    "def eval_batch(batch, model):\n",
    "    batch_inputs, batch_adjacency_matrix, batch_labels = (\n",
    "        batch.x.float(),\n",
    "        batch.edge_index,\n",
    "        batch.y.float(),\n",
    "    )\n",
    "    return model(batch_inputs, batch_adjacency_matrix), batch_labels\n",
    "pd.DataFrame(b0.x).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
