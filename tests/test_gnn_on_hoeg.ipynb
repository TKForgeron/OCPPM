{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Development/OCPPM/.env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.13.1+cu117\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.3.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python native\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/tim/Development/OCPPM/\")\n",
    "import logging\n",
    "import pickle\n",
    "import random\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from statistics import median as median\n",
    "from sys import platform\n",
    "from typing import Any, Callable\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import ocpa.algo.predictive_monitoring.factory as feature_factory\n",
    "\n",
    "# PyG\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "import torch.utils.tensorboard\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Object centric process mining\n",
    "from ocpa.algo.predictive_monitoring.obj import Feature_Storage as FeatureStorage\n",
    "\n",
    "# # Simple machine learning models, procedure tools, and evaluation metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader, HGTLoader\n",
    "from torch_geometric.nn import GATConv, Linear, to_hetero\n",
    "from torch_geometric.sampler import HeteroSamplerOutput, HGTSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom imports\n",
    "from config.files.bpi17 import bpi17_config\n",
    "from experiment.feature_encodings.hoeg.hoeg import HOEG\n",
    "from experiment.models.heterogeneous_models import GAT, HCGNN\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    filename=\"logging/debug.log\",\n",
    ")\n",
    "logging.critical(f\"{'-' * 32} NEW RUN {'-' * 32}\")\n",
    "\n",
    "# Config\n",
    "storage_path = \"data/BPI17/feature_encodings/HOEG/hoeg\"\n",
    "split_feature_storage_file = \"BPI2017-feature_storage-split-[C1-3,C5,P1-6,O2,O3,O5].fs\"\n",
    "objects_data_file = \"bpi17_ofg+oi_graph+app_node_map+off_node_map.pkl\"\n",
    "target_label = (feature_factory.EVENT_REMAINING_TIME, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: torch.nn.Module) -> int:\n",
    "    # with torch.no_grad():  # Initialize lazy modules.\n",
    "    #     out = model(data.x_dict, data.edge_index_dict)\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def prepare_dataloaders(\n",
    "    batch_size: int,\n",
    "    ds_train: HOEG = None,\n",
    "    ds_val: HOEG = None,\n",
    "    ds_test: HOEG = None,\n",
    "    shuffle: bool = True,\n",
    "    pin_memory: bool = True,\n",
    "    num_workers: int = 4,\n",
    "    seed_worker: Callable[[int], None] = None,\n",
    "    generator: torch.Generator = None,\n",
    ") -> list[DataLoader]:\n",
    "    dataloaders = []\n",
    "    if ds_train:\n",
    "        train_loader = DataLoader(\n",
    "            ds_train,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            pin_memory=pin_memory,\n",
    "            num_workers=num_workers,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=generator,\n",
    "        )\n",
    "        dataloaders.append(train_loader)\n",
    "    if ds_val:\n",
    "        val_loader = DataLoader(\n",
    "            ds_val,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            pin_memory=pin_memory,\n",
    "            num_workers=num_workers,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=generator,\n",
    "        )\n",
    "        dataloaders.append(val_loader)\n",
    "    if ds_test:\n",
    "        test_loader = DataLoader(\n",
    "            ds_test,\n",
    "            batch_size=128,\n",
    "            shuffle=shuffle,\n",
    "            pin_memory=pin_memory,\n",
    "            num_workers=num_workers,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=generator,\n",
    "        )\n",
    "        dataloaders.append(test_loader)\n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    epoch_index: int,\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    tb_writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    verbose: bool = True,\n",
    ") -> float:\n",
    "    if verbose:\n",
    "        print(f\"EPOCH {epoch_index + 1}:\")\n",
    "\n",
    "    # Enumerate over the data\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        # Use GPU\n",
    "        batch.to(device)\n",
    "\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, adjacency_matrix, labels = (\n",
    "            batch.x_dict,  # k times the batch_size, where k is the subgraph size\n",
    "            batch.edge_index_dict,\n",
    "            batch[\"event\"].y\n",
    "        )\n",
    "        # Reset gradients (set_to_none is faster than to zero)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # Passing the node features and the connection info\n",
    "        outputs = model(inputs, adjacency_matrix)\n",
    "        # Compute loss and gradients\n",
    "        loss = loss_fn(torch.squeeze(outputs[\"event\"]), labels)\n",
    "        loss.backward()\n",
    "        # Adjust learnable weights\n",
    "        optimizer.step()\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000  # loss per batch\n",
    "            if verbose:\n",
    "                print(f\"  batch {i + 1} loss: {last_loss}\")\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    num_epochs: int,\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    validation_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    device: torch.device,\n",
    "    verbose: bool = True,\n",
    ") -> str:\n",
    "    model_path = f\"models/{str(model).split('(')[0]}_{datetime.now().strftime('%Y%m%d_%Hh%Mm')}\"\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    writer = SummaryWriter(f\"{model_path}/run\")\n",
    "    best_vloss = 1_000_000_000_000_000.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(\n",
    "            epoch, model, train_loader, optimizer, loss_fn, writer, device\n",
    "        )\n",
    "\n",
    "        # We don't need gradients on to do reporting\n",
    "        model.train(False)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        num_batches = 0 # this will count up the number of batches\n",
    "        for num_batches, vbatch in enumerate(validation_loader, start=1):\n",
    "            vbatch.to(device)\n",
    "            vinputs, vadjacency_matrix, vlabels = (\n",
    "                vbatch.x_dict,\n",
    "                vbatch.edge_index_dict,\n",
    "                vbatch['event'].y,\n",
    "            )\n",
    "            voutputs = model(vinputs, vadjacency_matrix)\n",
    "            vloss = loss_fn(voutputs['event'], vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / num_batches\n",
    "        if verbose:\n",
    "            print(f\"LOSS train {avg_loss} valid {avg_vloss}\")\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars(\n",
    "            \"Training vs. Validation Loss\",\n",
    "            {\"Training\": avg_loss, \"Validation\": avg_vloss},\n",
    "            epoch + 1,\n",
    "        )\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(model.state_dict(), f\"{model_path}/state_dict_epoch{epoch}.pt\")\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    metric: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    "    verbose: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "\n",
    "        def _eval_batch(batch, model):\n",
    "\n",
    "            batch_inputs, batch_adjacency_matrix, batch_labels = (\n",
    "                batch.x_dict,  # k times the batch_size, where k is the subgraph size\n",
    "                batch.edge_index_dict,\n",
    "                batch[\"event\"].y\n",
    "            )\n",
    "            return model(batch_inputs, batch_adjacency_matrix), batch_labels\n",
    "\n",
    "        model.eval()\n",
    "        model.train(False)\n",
    "        model.to(device)\n",
    "        y_preds = torch.tensor([]).to(device)\n",
    "        y_true = torch.tensor([]).to(device)\n",
    "        for batch in tqdm(dataloader, disable=not(verbose)):\n",
    "            batch.to(device)\n",
    "            batch_y_preds, batch_y_true = _eval_batch(batch, model)\n",
    "            y_preds = torch.cat((y_preds, batch_y_preds))\n",
    "            y_true = torch.cat((y_true, batch_y_true))\n",
    "        y_preds = torch.squeeze(y_preds)\n",
    "    return metric(y_preds.to(device), y_true.to(device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = HOEG(\n",
    "    train=True,\n",
    "    root=storage_path,\n",
    "    events_filename=split_feature_storage_file,\n",
    "    objects_filename=objects_data_file,\n",
    "    label_key=target_label,\n",
    "    verbosity=51,\n",
    "    transform=T.ToUndirected()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = HOEG(\n",
    "    validation=True,\n",
    "    root=storage_path,\n",
    "    events_filename=split_feature_storage_file,\n",
    "    objects_filename=objects_data_file,\n",
    "    label_key=target_label,\n",
    "    verbosity=51,\n",
    "    transform=T.ToUndirected()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test = HOEG(\n",
    "#     test=True,\n",
    "#     root=storage_path,\n",
    "#     events_filename=split_feature_storage_file,\n",
    "#     objects_filename=objects_data_file,\n",
    "#     label_key=target_label,\n",
    "#     verbosity=51,\n",
    "#     transform=T.ToUndirected()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = prepare_dataloaders(512, ds_train, ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND OUT WHY GETTING ERROR '...negative dimension...' \n",
    "# bc all is equal to the GAT in run_ofg.ipynb\n",
    "\n",
    "meta_data = (\n",
    "            [\"event\", \"application\", \"offer\"],\n",
    "            [\n",
    "                (\"event\", \"follows\", \"event\"),\n",
    "                (\"event\", \"interacts\", \"application\"),\n",
    "                (\"event\", \"interacts\", \"offer\"),\n",
    "                (\"application\", \"interacts\", \"application\"),\n",
    "                (\"application\", \"rev_interacts\", \"event\"),\n",
    "                (\"offer\", \"rev_interacts\", \"event\"),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.lin1 = Linear(-1, hidden_channels)\n",
    "        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n",
    "        self.lin2 = Linear(-1, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index) + self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index) + self.lin2(x)\n",
    "        return x\n",
    "\n",
    "model = GAT(hidden_channels=64, out_channels=1)\n",
    "model = to_hetero(model, meta_data, aggr=\"sum\")\n",
    "# model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (event): Linear(-1, 1, bias=True)\n",
       "  (application): Linear(-1, 1, bias=True)\n",
       "  (offer): Linear(-1, 1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch0 =  next(iter(train_loader))\n",
    "batch0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
